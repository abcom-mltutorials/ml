{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phhCHW7vQBK8"
      },
      "source": [
        "# MLBox\n",
        "\n",
        "Requires training/validation/testing datasets in csv format. The inference too is spilled into csv. \n",
        "\n",
        "https://mlbox.readthedocs.io/en/latest/introduction.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5nRwzoi5hll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67b10179-f140-4d2b-9335-341f741e4b60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlbox in /usr/local/lib/python3.7/dist-packages (0.8.5)\n",
            "Requirement already satisfied: lightgbm==2.3.1 in /usr/local/lib/python3.7/dist-packages (from mlbox) (2.3.1)\n",
            "Requirement already satisfied: matplotlib==3.0.3 in /usr/local/lib/python3.7/dist-packages (from mlbox) (3.0.3)\n",
            "Requirement already satisfied: numpy==1.18.2 in /usr/local/lib/python3.7/dist-packages (from mlbox) (1.18.2)\n",
            "Requirement already satisfied: pandas==0.25.3 in /usr/local/lib/python3.7/dist-packages (from mlbox) (0.25.3)\n",
            "Requirement already satisfied: xlrd==1.2.0 in /usr/local/lib/python3.7/dist-packages (from mlbox) (1.2.0)\n",
            "Collecting scikit-learn==0.22.1\n",
            "  Using cached scikit_learn-0.22.1-cp37-cp37m-manylinux1_x86_64.whl (7.0 MB)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from mlbox) (1.4.1)\n",
            "Requirement already satisfied: hyperopt==0.2.3 in /usr/local/lib/python3.7/dist-packages (from mlbox) (0.2.3)\n",
            "Requirement already satisfied: tensorflow==2.0.0 in /usr/local/lib/python3.7/dist-packages (from mlbox) (2.0.0)\n",
            "Requirement already satisfied: tables==3.5.2 in /usr/local/lib/python3.7/dist-packages (from mlbox) (3.5.2)\n",
            "Requirement already satisfied: joblib==0.14.1 in /usr/local/lib/python3.7/dist-packages (from mlbox) (0.14.1)\n",
            "Requirement already satisfied: networkx==2.2 in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.2.3->mlbox) (2.2)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.2.3->mlbox) (1.3.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.2.3->mlbox) (4.62.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.2.3->mlbox) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hyperopt==0.2.3->mlbox) (1.15.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0.3->mlbox) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0.3->mlbox) (1.3.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0.3->mlbox) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib==3.0.3->mlbox) (3.0.7)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx==2.2->hyperopt==0.2.3->mlbox) (4.4.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->mlbox) (2018.9)\n",
            "Requirement already satisfied: mock>=2.0 in /usr/local/lib/python3.7/dist-packages (from tables==3.5.2->mlbox) (4.0.3)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.7/dist-packages (from tables==3.5.2->mlbox) (2.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (1.1.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (3.17.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (2.0.1)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (0.2.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (2.0.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (1.13.3)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (1.43.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (1.0.8)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (0.37.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.0.0->mlbox) (1.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0->mlbox) (3.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr>=2.6.2->tables==3.5.2->mlbox) (21.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (1.35.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (57.4.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (3.3.6)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (0.4.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (2.23.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (4.10.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (3.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (3.10.0.2)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0->mlbox) (3.1.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==2.0.0->mlbox) (1.5.2)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.18.2 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.1 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-0.22.1\n"
          ]
        }
      ],
      "source": [
        "!pip install mlbox"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Restart the runtime before proceeding***"
      ],
      "metadata": {
        "id": "DEeHJFUmNEkC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qWrZ70S8Wmsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97bf1186-c94c-44a5-c9c1-ccd4567e3dca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imblearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.7/dist-packages (from imblearn) (0.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (0.14.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.18.2)\n",
            "Collecting scikit-learn>=0.24\n",
            "  Using cached scikit_learn-1.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (24.8 MB)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from imbalanced-learn->imblearn) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (3.0.0)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.1\n",
            "    Uninstalling scikit-learn-0.22.1:\n",
            "      Successfully uninstalled scikit-learn-0.22.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mlbox 0.8.5 requires scikit-learn==0.22.1, but you have scikit-learn 1.0.2 which is incompatible.\n",
            "kapre 0.3.7 requires numpy>=1.18.5, but you have numpy 1.18.2 which is incompatible.\u001b[0m\n",
            "Successfully installed scikit-learn-1.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install imblearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5v7U_BVh5lY1"
      },
      "outputs": [],
      "source": [
        "from mlbox.preprocessing import *\n",
        "from mlbox.optimisation import *\n",
        "from mlbox.prediction import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vQ515fsGlNV2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.utils import plot_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80C643inHKNz"
      },
      "source": [
        "## Setting up dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9hztLXKv2Kn"
      },
      "source": [
        "## Superconductors dataset (regression task)\n",
        "\n",
        "Source: https://archive.ics.uci.edu/ml/datasets/Superconductivty+Data\n",
        "\n",
        "\n",
        "The dataset contains 81 numerical features of 21263 superconductors. The label corresponds to their critical temperature measured in Kelvin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTDrL4iwv2Kq",
        "outputId": "d2b9f4d3-81cc-4b17-b33f-462454dbd292"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-02 12:59:27--  https://raw.githubusercontent.com/abcom-mltutorials/automl/main/superconductors.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 23859780 (23M) [text/plain]\n",
            "Saving to: ‘superconductors.csv’\n",
            "\n",
            "superconductors.csv 100%[===================>]  22.75M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2022-02-02 12:59:27 (356 MB/s) - ‘superconductors.csv’ saved [23859780/23859780]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://raw.githubusercontent.com/abcom-mltutorials/automl/main/superconductors.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y__xwS0D7eHC"
      },
      "outputs": [],
      "source": [
        "regressor_df=pd.read_csv('/content/superconductors.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regressor_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqedHGLCtCh9",
        "outputId": "4ce840fc-4be2-4844-d53b-d74492c09fb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21263, 82)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a41vlLivv2K7"
      },
      "outputs": [],
      "source": [
        "features_regressor = regressor_df.iloc[:,:-1]\n",
        "label_regressor = regressor_df.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pxQwzGxUwEfA"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKhmEiOGv2K-"
      },
      "outputs": [],
      "source": [
        "X_train_regressor, X_test_regressor, label_train_regressor, label_test_regressor = train_test_split(features_regressor, label_regressor, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q9BMsYBa76gQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "def error_metrics(y_pred,y_val):\n",
        "  print('MSE: ',mean_squared_error(y_pred,y_val))\n",
        "  print('RMSE: ',np.sqrt(mean_squared_error(y_pred,y_val)))\n",
        "  print('Coefficient of determination: ',r2_score(y_pred,y_val))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JUQFDPa7QM2s"
      },
      "source": [
        "## Regressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-aDEOGJ7rjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f07a3bc-443d-468b-ae2c-eb781b62d58d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17010, 81), (17010,))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "X_train_regressor.shape, label_train_regressor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jnCyVhRFAsS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "6e55be64-ae39-4401-874a-b210574583d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-30cc450d-29cc-4208-846c-0e7f4ea1dcc7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number_of_elements</th>\n",
              "      <th>mean_atomic_mass</th>\n",
              "      <th>wtd_mean_atomic_mass</th>\n",
              "      <th>gmean_atomic_mass</th>\n",
              "      <th>wtd_gmean_atomic_mass</th>\n",
              "      <th>entropy_atomic_mass</th>\n",
              "      <th>wtd_entropy_atomic_mass</th>\n",
              "      <th>range_atomic_mass</th>\n",
              "      <th>wtd_range_atomic_mass</th>\n",
              "      <th>std_atomic_mass</th>\n",
              "      <th>wtd_std_atomic_mass</th>\n",
              "      <th>mean_fie</th>\n",
              "      <th>wtd_mean_fie</th>\n",
              "      <th>gmean_fie</th>\n",
              "      <th>wtd_gmean_fie</th>\n",
              "      <th>entropy_fie</th>\n",
              "      <th>wtd_entropy_fie</th>\n",
              "      <th>range_fie</th>\n",
              "      <th>wtd_range_fie</th>\n",
              "      <th>std_fie</th>\n",
              "      <th>wtd_std_fie</th>\n",
              "      <th>mean_atomic_radius</th>\n",
              "      <th>wtd_mean_atomic_radius</th>\n",
              "      <th>gmean_atomic_radius</th>\n",
              "      <th>wtd_gmean_atomic_radius</th>\n",
              "      <th>entropy_atomic_radius</th>\n",
              "      <th>wtd_entropy_atomic_radius</th>\n",
              "      <th>range_atomic_radius</th>\n",
              "      <th>wtd_range_atomic_radius</th>\n",
              "      <th>std_atomic_radius</th>\n",
              "      <th>wtd_std_atomic_radius</th>\n",
              "      <th>mean_Density</th>\n",
              "      <th>wtd_mean_Density</th>\n",
              "      <th>gmean_Density</th>\n",
              "      <th>wtd_gmean_Density</th>\n",
              "      <th>entropy_Density</th>\n",
              "      <th>wtd_entropy_Density</th>\n",
              "      <th>range_Density</th>\n",
              "      <th>wtd_range_Density</th>\n",
              "      <th>std_Density</th>\n",
              "      <th>...</th>\n",
              "      <th>mean_ElectronAffinity</th>\n",
              "      <th>wtd_mean_ElectronAffinity</th>\n",
              "      <th>gmean_ElectronAffinity</th>\n",
              "      <th>wtd_gmean_ElectronAffinity</th>\n",
              "      <th>entropy_ElectronAffinity</th>\n",
              "      <th>wtd_entropy_ElectronAffinity</th>\n",
              "      <th>range_ElectronAffinity</th>\n",
              "      <th>wtd_range_ElectronAffinity</th>\n",
              "      <th>std_ElectronAffinity</th>\n",
              "      <th>wtd_std_ElectronAffinity</th>\n",
              "      <th>mean_FusionHeat</th>\n",
              "      <th>wtd_mean_FusionHeat</th>\n",
              "      <th>gmean_FusionHeat</th>\n",
              "      <th>wtd_gmean_FusionHeat</th>\n",
              "      <th>entropy_FusionHeat</th>\n",
              "      <th>wtd_entropy_FusionHeat</th>\n",
              "      <th>range_FusionHeat</th>\n",
              "      <th>wtd_range_FusionHeat</th>\n",
              "      <th>std_FusionHeat</th>\n",
              "      <th>wtd_std_FusionHeat</th>\n",
              "      <th>mean_ThermalConductivity</th>\n",
              "      <th>wtd_mean_ThermalConductivity</th>\n",
              "      <th>gmean_ThermalConductivity</th>\n",
              "      <th>wtd_gmean_ThermalConductivity</th>\n",
              "      <th>entropy_ThermalConductivity</th>\n",
              "      <th>wtd_entropy_ThermalConductivity</th>\n",
              "      <th>range_ThermalConductivity</th>\n",
              "      <th>wtd_range_ThermalConductivity</th>\n",
              "      <th>std_ThermalConductivity</th>\n",
              "      <th>wtd_std_ThermalConductivity</th>\n",
              "      <th>mean_Valence</th>\n",
              "      <th>wtd_mean_Valence</th>\n",
              "      <th>gmean_Valence</th>\n",
              "      <th>wtd_gmean_Valence</th>\n",
              "      <th>entropy_Valence</th>\n",
              "      <th>wtd_entropy_Valence</th>\n",
              "      <th>range_Valence</th>\n",
              "      <th>wtd_range_Valence</th>\n",
              "      <th>std_Valence</th>\n",
              "      <th>wtd_std_Valence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>16546</th>\n",
              "      <td>2</td>\n",
              "      <td>77.143500</td>\n",
              "      <td>53.722300</td>\n",
              "      <td>71.372307</td>\n",
              "      <td>51.848347</td>\n",
              "      <td>0.619298</td>\n",
              "      <td>0.497747</td>\n",
              "      <td>58.55300</td>\n",
              "      <td>32.438300</td>\n",
              "      <td>29.276500</td>\n",
              "      <td>17.565900</td>\n",
              "      <td>730.650000</td>\n",
              "      <td>672.370000</td>\n",
              "      <td>727.009147</td>\n",
              "      <td>671.093559</td>\n",
              "      <td>0.688168</td>\n",
              "      <td>0.365933</td>\n",
              "      <td>145.7</td>\n",
              "      <td>511.670000</td>\n",
              "      <td>72.850000</td>\n",
              "      <td>43.710000</td>\n",
              "      <td>172.500000</td>\n",
              "      <td>175.300000</td>\n",
              "      <td>172.464489</td>\n",
              "      <td>175.287147</td>\n",
              "      <td>0.692941</td>\n",
              "      <td>0.317114</td>\n",
              "      <td>7</td>\n",
              "      <td>141.500000</td>\n",
              "      <td>3.500000</td>\n",
              "      <td>2.100000</td>\n",
              "      <td>8265.000000</td>\n",
              "      <td>5258.600000</td>\n",
              "      <td>7361.226868</td>\n",
              "      <td>4971.644733</td>\n",
              "      <td>0.585882</td>\n",
              "      <td>0.537622</td>\n",
              "      <td>7516.000</td>\n",
              "      <td>2854.000000</td>\n",
              "      <td>3758.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>32.150000</td>\n",
              "      <td>13.710000</td>\n",
              "      <td>22.412497</td>\n",
              "      <td>10.897607</td>\n",
              "      <td>0.407721</td>\n",
              "      <td>0.674062</td>\n",
              "      <td>46.10</td>\n",
              "      <td>2.670000</td>\n",
              "      <td>23.050000</td>\n",
              "      <td>13.830000</td>\n",
              "      <td>17.700000</td>\n",
              "      <td>18.500000</td>\n",
              "      <td>17.671729</td>\n",
              "      <td>18.489667</td>\n",
              "      <td>0.691550</td>\n",
              "      <td>0.303163</td>\n",
              "      <td>2.000</td>\n",
              "      <td>15.160000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>46.500000</td>\n",
              "      <td>26.900000</td>\n",
              "      <td>39.522146</td>\n",
              "      <td>24.734677</td>\n",
              "      <td>0.547081</td>\n",
              "      <td>0.577138</td>\n",
              "      <td>49.00000</td>\n",
              "      <td>12.700000</td>\n",
              "      <td>24.500000</td>\n",
              "      <td>14.700000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.693147</td>\n",
              "      <td>0.325083</td>\n",
              "      <td>0</td>\n",
              "      <td>3.200000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5970</th>\n",
              "      <td>4</td>\n",
              "      <td>104.365600</td>\n",
              "      <td>71.922350</td>\n",
              "      <td>72.746865</td>\n",
              "      <td>43.369558</td>\n",
              "      <td>1.129463</td>\n",
              "      <td>1.221243</td>\n",
              "      <td>184.59060</td>\n",
              "      <td>26.332050</td>\n",
              "      <td>70.392496</td>\n",
              "      <td>65.568217</td>\n",
              "      <td>891.650000</td>\n",
              "      <td>994.525000</td>\n",
              "      <td>838.584885</td>\n",
              "      <td>923.668549</td>\n",
              "      <td>1.328085</td>\n",
              "      <td>1.012874</td>\n",
              "      <td>810.6</td>\n",
              "      <td>555.950000</td>\n",
              "      <td>301.512840</td>\n",
              "      <td>347.303530</td>\n",
              "      <td>154.250000</td>\n",
              "      <td>126.100000</td>\n",
              "      <td>131.729022</td>\n",
              "      <td>97.477764</td>\n",
              "      <td>1.260175</td>\n",
              "      <td>1.235910</td>\n",
              "      <td>205</td>\n",
              "      <td>46.150000</td>\n",
              "      <td>73.155229</td>\n",
              "      <td>85.620617</td>\n",
              "      <td>6501.357250</td>\n",
              "      <td>3575.614500</td>\n",
              "      <td>883.117278</td>\n",
              "      <td>93.289274</td>\n",
              "      <td>0.977862</td>\n",
              "      <td>1.081982</td>\n",
              "      <td>13532.571</td>\n",
              "      <td>1352.685500</td>\n",
              "      <td>5164.791227</td>\n",
              "      <td>...</td>\n",
              "      <td>69.837500</td>\n",
              "      <td>93.247500</td>\n",
              "      <td>25.084962</td>\n",
              "      <td>50.532590</td>\n",
              "      <td>0.894571</td>\n",
              "      <td>0.665238</td>\n",
              "      <td>141.00</td>\n",
              "      <td>71.100000</td>\n",
              "      <td>62.076781</td>\n",
              "      <td>60.616259</td>\n",
              "      <td>5.903000</td>\n",
              "      <td>4.305000</td>\n",
              "      <td>2.701702</td>\n",
              "      <td>1.266261</td>\n",
              "      <td>0.963720</td>\n",
              "      <td>0.964520</td>\n",
              "      <td>12.878</td>\n",
              "      <td>1.889000</td>\n",
              "      <td>5.037900</td>\n",
              "      <td>4.874169</td>\n",
              "      <td>106.581645</td>\n",
              "      <td>65.343290</td>\n",
              "      <td>6.313081</td>\n",
              "      <td>1.019324</td>\n",
              "      <td>0.270718</td>\n",
              "      <td>0.319780</td>\n",
              "      <td>399.97342</td>\n",
              "      <td>59.986710</td>\n",
              "      <td>169.524558</td>\n",
              "      <td>140.776929</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.386294</td>\n",
              "      <td>1.207974</td>\n",
              "      <td>0</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7542</th>\n",
              "      <td>5</td>\n",
              "      <td>74.231650</td>\n",
              "      <td>51.256952</td>\n",
              "      <td>60.515221</td>\n",
              "      <td>34.941384</td>\n",
              "      <td>1.453747</td>\n",
              "      <td>1.327852</td>\n",
              "      <td>121.32760</td>\n",
              "      <td>20.724892</td>\n",
              "      <td>39.445875</td>\n",
              "      <td>44.195499</td>\n",
              "      <td>816.360000</td>\n",
              "      <td>1004.612615</td>\n",
              "      <td>771.891022</td>\n",
              "      <td>938.687448</td>\n",
              "      <td>1.552506</td>\n",
              "      <td>0.915890</td>\n",
              "      <td>810.6</td>\n",
              "      <td>701.479692</td>\n",
              "      <td>282.395259</td>\n",
              "      <td>341.879109</td>\n",
              "      <td>160.000000</td>\n",
              "      <td>114.520000</td>\n",
              "      <td>139.595299</td>\n",
              "      <td>89.673653</td>\n",
              "      <td>1.501218</td>\n",
              "      <td>1.375101</td>\n",
              "      <td>205</td>\n",
              "      <td>38.049231</td>\n",
              "      <td>69.922815</td>\n",
              "      <td>79.228649</td>\n",
              "      <td>4816.685800</td>\n",
              "      <td>2941.261769</td>\n",
              "      <td>1074.903488</td>\n",
              "      <td>66.249535</td>\n",
              "      <td>1.322213</td>\n",
              "      <td>0.886765</td>\n",
              "      <td>8958.571</td>\n",
              "      <td>2011.784385</td>\n",
              "      <td>3084.729342</td>\n",
              "      <td>...</td>\n",
              "      <td>62.090000</td>\n",
              "      <td>108.440615</td>\n",
              "      <td>26.186824</td>\n",
              "      <td>84.237345</td>\n",
              "      <td>1.130428</td>\n",
              "      <td>0.759361</td>\n",
              "      <td>141.00</td>\n",
              "      <td>76.721538</td>\n",
              "      <td>57.644743</td>\n",
              "      <td>50.149563</td>\n",
              "      <td>8.014400</td>\n",
              "      <td>5.214923</td>\n",
              "      <td>4.549685</td>\n",
              "      <td>1.332174</td>\n",
              "      <td>1.384657</td>\n",
              "      <td>1.091194</td>\n",
              "      <td>12.878</td>\n",
              "      <td>2.897231</td>\n",
              "      <td>4.438215</td>\n",
              "      <td>5.617195</td>\n",
              "      <td>111.005316</td>\n",
              "      <td>94.675851</td>\n",
              "      <td>13.131173</td>\n",
              "      <td>1.088203</td>\n",
              "      <td>0.785624</td>\n",
              "      <td>0.251330</td>\n",
              "      <td>399.97342</td>\n",
              "      <td>89.831842</td>\n",
              "      <td>150.600199</td>\n",
              "      <td>164.728982</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>2.076923</td>\n",
              "      <td>2.168944</td>\n",
              "      <td>2.063362</td>\n",
              "      <td>1.594167</td>\n",
              "      <td>1.229147</td>\n",
              "      <td>1</td>\n",
              "      <td>1.064615</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.266469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2157</th>\n",
              "      <td>7</td>\n",
              "      <td>88.309607</td>\n",
              "      <td>48.586910</td>\n",
              "      <td>69.138309</td>\n",
              "      <td>33.542945</td>\n",
              "      <td>1.740703</td>\n",
              "      <td>1.724444</td>\n",
              "      <td>191.20060</td>\n",
              "      <td>11.938538</td>\n",
              "      <td>57.329551</td>\n",
              "      <td>45.189822</td>\n",
              "      <td>726.442857</td>\n",
              "      <td>1005.639231</td>\n",
              "      <td>694.260169</td>\n",
              "      <td>942.995772</td>\n",
              "      <td>1.895033</td>\n",
              "      <td>1.038901</td>\n",
              "      <td>764.1</td>\n",
              "      <td>698.469231</td>\n",
              "      <td>249.458728</td>\n",
              "      <td>337.508375</td>\n",
              "      <td>161.142857</td>\n",
              "      <td>109.165385</td>\n",
              "      <td>147.320208</td>\n",
              "      <td>87.738692</td>\n",
              "      <td>1.878663</td>\n",
              "      <td>1.671235</td>\n",
              "      <td>171</td>\n",
              "      <td>31.292308</td>\n",
              "      <td>53.656124</td>\n",
              "      <td>69.964383</td>\n",
              "      <td>5180.489857</td>\n",
              "      <td>2780.000231</td>\n",
              "      <td>1526.892841</td>\n",
              "      <td>61.344330</td>\n",
              "      <td>1.615339</td>\n",
              "      <td>1.295904</td>\n",
              "      <td>11338.571</td>\n",
              "      <td>1549.999769</td>\n",
              "      <td>3850.216319</td>\n",
              "      <td>...</td>\n",
              "      <td>52.985714</td>\n",
              "      <td>101.848462</td>\n",
              "      <td>28.410697</td>\n",
              "      <td>65.146666</td>\n",
              "      <td>1.492706</td>\n",
              "      <td>0.733149</td>\n",
              "      <td>138.63</td>\n",
              "      <td>76.581923</td>\n",
              "      <td>51.155793</td>\n",
              "      <td>56.253081</td>\n",
              "      <td>7.041714</td>\n",
              "      <td>4.636500</td>\n",
              "      <td>4.462156</td>\n",
              "      <td>1.240009</td>\n",
              "      <td>1.719581</td>\n",
              "      <td>1.392176</td>\n",
              "      <td>12.878</td>\n",
              "      <td>2.217154</td>\n",
              "      <td>4.222917</td>\n",
              "      <td>5.196820</td>\n",
              "      <td>109.860940</td>\n",
              "      <td>85.718158</td>\n",
              "      <td>23.212427</td>\n",
              "      <td>1.175396</td>\n",
              "      <td>1.294800</td>\n",
              "      <td>0.733572</td>\n",
              "      <td>399.97342</td>\n",
              "      <td>69.216457</td>\n",
              "      <td>133.618336</td>\n",
              "      <td>149.124166</td>\n",
              "      <td>2.571429</td>\n",
              "      <td>2.138462</td>\n",
              "      <td>2.479397</td>\n",
              "      <td>2.104979</td>\n",
              "      <td>1.908037</td>\n",
              "      <td>1.479833</td>\n",
              "      <td>2</td>\n",
              "      <td>1.030769</td>\n",
              "      <td>0.728431</td>\n",
              "      <td>0.451559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18265</th>\n",
              "      <td>5</td>\n",
              "      <td>69.321369</td>\n",
              "      <td>72.150027</td>\n",
              "      <td>56.104529</td>\n",
              "      <td>55.643005</td>\n",
              "      <td>1.434383</td>\n",
              "      <td>1.302362</td>\n",
              "      <td>124.90825</td>\n",
              "      <td>31.227062</td>\n",
              "      <td>40.715396</td>\n",
              "      <td>45.074073</td>\n",
              "      <td>860.620000</td>\n",
              "      <td>886.175000</td>\n",
              "      <td>822.540740</td>\n",
              "      <td>839.406274</td>\n",
              "      <td>1.564269</td>\n",
              "      <td>1.464385</td>\n",
              "      <td>786.5</td>\n",
              "      <td>271.417500</td>\n",
              "      <td>262.468325</td>\n",
              "      <td>287.831000</td>\n",
              "      <td>143.400000</td>\n",
              "      <td>140.950000</td>\n",
              "      <td>126.229902</td>\n",
              "      <td>120.266822</td>\n",
              "      <td>1.501198</td>\n",
              "      <td>1.415852</td>\n",
              "      <td>199</td>\n",
              "      <td>50.350000</td>\n",
              "      <td>64.701159</td>\n",
              "      <td>72.124528</td>\n",
              "      <td>5828.485800</td>\n",
              "      <td>5137.557250</td>\n",
              "      <td>1306.599783</td>\n",
              "      <td>816.244598</td>\n",
              "      <td>1.373048</td>\n",
              "      <td>1.339883</td>\n",
              "      <td>8898.571</td>\n",
              "      <td>1659.642750</td>\n",
              "      <td>3106.180080</td>\n",
              "      <td>...</td>\n",
              "      <td>71.180000</td>\n",
              "      <td>76.275000</td>\n",
              "      <td>57.963293</td>\n",
              "      <td>62.198993</td>\n",
              "      <td>1.438367</td>\n",
              "      <td>1.309987</td>\n",
              "      <td>125.30</td>\n",
              "      <td>32.615000</td>\n",
              "      <td>41.213270</td>\n",
              "      <td>43.271375</td>\n",
              "      <td>12.964400</td>\n",
              "      <td>12.335500</td>\n",
              "      <td>6.243314</td>\n",
              "      <td>4.978665</td>\n",
              "      <td>1.297086</td>\n",
              "      <td>1.171085</td>\n",
              "      <td>27.478</td>\n",
              "      <td>6.869500</td>\n",
              "      <td>9.246090</td>\n",
              "      <td>10.226571</td>\n",
              "      <td>48.405316</td>\n",
              "      <td>37.081645</td>\n",
              "      <td>10.641898</td>\n",
              "      <td>6.186597</td>\n",
              "      <td>1.214507</td>\n",
              "      <td>1.272564</td>\n",
              "      <td>99.97342</td>\n",
              "      <td>13.818355</td>\n",
              "      <td>37.933172</td>\n",
              "      <td>33.680510</td>\n",
              "      <td>3.600000</td>\n",
              "      <td>3.575000</td>\n",
              "      <td>3.437544</td>\n",
              "      <td>3.381939</td>\n",
              "      <td>1.567056</td>\n",
              "      <td>1.488545</td>\n",
              "      <td>3</td>\n",
              "      <td>0.950000</td>\n",
              "      <td>1.019804</td>\n",
              "      <td>1.115516</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 81 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-30cc450d-29cc-4208-846c-0e7f4ea1dcc7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-30cc450d-29cc-4208-846c-0e7f4ea1dcc7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-30cc450d-29cc-4208-846c-0e7f4ea1dcc7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       number_of_elements  mean_atomic_mass  ...  std_Valence  wtd_std_Valence\n",
              "16546                   2         77.143500  ...     0.000000         0.000000\n",
              "5970                    4        104.365600  ...     0.000000         0.000000\n",
              "7542                    5         74.231650  ...     0.400000         0.266469\n",
              "2157                    7         88.309607  ...     0.728431         0.451559\n",
              "18265                   5         69.321369  ...     1.019804         1.115516\n",
              "\n",
              "[5 rows x 81 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "X_train_regressor.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMKyTo5cFQXO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "00f0d51b-354a-490a-98f7-a5d628c82c7b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'critical_temp'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "label_train_regressor.name"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creat training/testing csv files "
      ],
      "metadata": {
        "id": "FhB7PMIQ_mQp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LORF-sjv_omo"
      },
      "outputs": [],
      "source": [
        "training1 = pd.concat([X_train_regressor, label_train_regressor], axis=1)\n",
        "training1.to_csv('training1_file.csv')\n",
        "\n",
        "testing1 = X_test_regressor\n",
        "testing1.to_csv('testing1_file.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0_11rqs7rb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b089205-8604-40bd-dc60-d35e8202b721"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(pandas.core.frame.DataFrame, pandas.core.frame.DataFrame)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "type(training1), type(testing1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Reader to load the files. Specify the target name. "
      ],
      "metadata": {
        "id": "7KQSB-BwANOv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1o3OPhkTE0nx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1c3b332-df05-40a8-e8e6-b59dbb68e792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "reading csv : training1_file.csv ...\n",
            "cleaning data ...\n",
            "CPU time: 7.175208568572998 seconds\n",
            "\n",
            "reading csv : testing1_file.csv ...\n",
            "cleaning data ...\n",
            "CPU time: 0.7768888473510742 seconds\n",
            "\n",
            "> Number of common features : 81\n",
            "\n",
            "gathering and crunching for train and test datasets ...\n",
            "reindexing for train and test datasets ...\n",
            "dropping training duplicates ...\n",
            "dropping constant variables on training set ...\n",
            "\n",
            "> Number of categorical features: 0\n",
            "> Number of numerical features: 81\n",
            "> Number of training samples : 16969\n",
            "> Number of test samples : 4253\n",
            "\n",
            "> You have no missing values on train set...\n",
            "\n",
            "> Task : regression\n",
            "count    16969.000000\n",
            "mean        34.588765\n",
            "std         34.350772\n",
            "min          0.000210\n",
            "25%          5.400000\n",
            "50%         20.000000\n",
            "75%         63.100000\n",
            "max        185.000000\n",
            "Name: critical_temp, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "paths=['training1_file.csv', 'testing1_file.csv']\n",
        "rd = Reader(sep = ',')\n",
        "df = rd.train_test_split(paths, target_name='critical_temp')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The function Drift_thresholder drops the biased columns"
      ],
      "metadata": {
        "id": "PlBznC5wCt3a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rCRu4f7rE0Yq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29eca46c-2f27-4900-8d40-2cb506ddd494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "computing drifts ...\n",
            "CPU time: 7.082433700561523 seconds\n",
            "\n",
            "> Top 10 drifts\n",
            "\n",
            "('std_ElectronAffinity', 0.02157671710918785)\n",
            "('wtd_entropy_atomic_mass', 0.020008185395496536)\n",
            "('range_atomic_radius', 0.019831484244556385)\n",
            "('number_of_elements', 0.01882200504925624)\n",
            "('mean_ElectronAffinity', 0.017523093873334172)\n",
            "('wtd_mean_Valence', 0.017311149698706618)\n",
            "('wtd_std_atomic_mass', 0.017067134516009386)\n",
            "('range_fie', 0.016194988933973864)\n",
            "('mean_Valence', 0.01413587864398913)\n",
            "('wtd_mean_atomic_mass', 0.014067340141108886)\n",
            "\n",
            "> Deleted variables : []\n",
            "> Drift coefficients dumped into directory : save\n"
          ]
        }
      ],
      "source": [
        "dft = Drift_thresholder()\n",
        "df = dft.fit_transform(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No columns were dropped. Set the range of values for the various hyper-parameters"
      ],
      "metadata": {
        "id": "M6elCYVtLLqy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jY7KnacFbTx"
      },
      "outputs": [],
      "source": [
        "space = {'ne__numerical_strategy':{\"space\":[0]},\n",
        "        'fs__strategy':{\"search\":\"choice\",\n",
        "                        \"space\":['l1','variance','rf_feature_importance']},\n",
        "        'fs__threshold':{\"search\":\"uniform\",\n",
        "                        \"space\":[0.01,0.3]},    \n",
        "        'est__strategy' : {\"search\":\"choice\",\n",
        "                           \"space\" : ['LightGBM', 'RandomForest', 'ExtraTrees', 'AdaBoost']},\n",
        "        'est__max_depth':{\"search\":\"choice\",\n",
        "                          \"space\":[3,4,5,6]},\n",
        "        'est__n_estimators':{\"search\":\"choice\",\n",
        "                             \"space\":[250,500,700]}}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the number of folds for cross-validation and the scoring, which could be rmse for regression and 'accuracy' for classification. We use the default value for scoring here. "
      ],
      "metadata": {
        "id": "ssW1IGhJMFEw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vIF9Zt8pFbHN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adade49f-28f5-4a70-b8b8-0f6f72df52cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlbox/optimisation/optimiser.py:74: UserWarning: Optimiser will save all your fitted models into directory 'save/joblib'. Please clear it regularly.\n",
            "  +str(self.to_path)+\"/joblib'. Please clear it regularly.\")\n"
          ]
        }
      ],
      "source": [
        "opt=Optimiser(n_folds=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first evaluate the model on a single run to check if all our parameters are set properly"
      ],
      "metadata": {
        "id": "mGmwnPl0Oy1j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPgDx3juF2x9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf170c36-561b-490d-d4d1-199c946a3330"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No parameters set. Default configuration is tested\n",
            "\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            "\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            "\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            "\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "\n",
            "\n",
            "MEAN SCORE : neg_mean_squared_error = -101.07097508536515\n",
            "VARIANCE : 3.9228381608006457 (fold 1 = -98.49980313353328, fold 2 = -106.61388357071533, fold 3 = -98.09923855184684)\n",
            "CPU time: 36.4693648815155 seconds\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-101.07097508536515"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "opt.evaluate(None, df)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "tic = time.perf_counter()"
      ],
      "metadata": {
        "id": "t-_C1XSLRcgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As the tool worked fine for one evaluation we can now run for 20 number of trials"
      ],
      "metadata": {
        "id": "28sGUFuYPj-4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lrx0RWcF2oy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2ccce59-13eb-474b-d03d-bc8fb4c071e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.234943726959232}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 4, 'n_estimators': 250, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_mean_squared_error = -133.54346968437372\n",
            "VARIANCE : 5.442638378410518 (fold 1 = -133.21632744038556, fold 2 = -140.3668607920258, fold 3 = -127.04722082070984)\n",
            "CPU time: 6.415622711181641 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.24984080390121666}\n",
            ">>> ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 4, 'n_estimators': 500, 'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
            "MEAN SCORE : neg_mean_squared_error = -428.6804127252928\n",
            "VARIANCE : 7.172759824560664 (fold 1 = -429.57593183256995, fold 2 = -436.9831536943456, fold 3 = -419.4821526489627)\n",
            "CPU time: 63.99905800819397 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.07036662138756665}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'n_estimators': 250, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_mean_squared_error = -119.41289653897945\n",
            "VARIANCE : 5.1794518467232 (fold 1 = -119.70796266824439, fold 2 = -125.60372163189118, fold 3 = -112.92700531680279)\n",
            "CPU time: 4.967947244644165 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.08710336839150974}\n",
            ">>> ESTIMATOR :{'strategy': 'RandomForest', 'max_depth': 4, 'n_estimators': 500, 'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
            "MEAN SCORE : neg_mean_squared_error = -293.4863922021293\n",
            "VARIANCE : 6.661293119510183 (fold 1 = -289.51927692378644, fold 2 = -302.8696617486864, fold 3 = -288.07023793391517)\n",
            "CPU time: 79.27534198760986 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.2626927656408281}\n",
            ">>> ESTIMATOR :{'strategy': 'RandomForest', 'max_depth': 5, 'n_estimators': 250, 'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
            "MEAN SCORE : neg_mean_squared_error = -255.08041724373027\n",
            "VARIANCE : 4.570413851349196 (fold 1 = -253.98570483746934, fold 2 = -261.14449599920925, fold 3 = -250.11105089451223)\n",
            "CPU time: 15.102295398712158 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.1660678886036081}\n",
            ">>> ESTIMATOR :{'strategy': 'RandomForest', 'max_depth': 6, 'n_estimators': 500, 'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
            "MEAN SCORE : neg_mean_squared_error = -224.53435003413878\n",
            "VARIANCE : 4.760617273981541 (fold 1 = -220.9137938838404, fold 2 = -231.26030660934262, fold 3 = -221.42894960923329)\n",
            "CPU time: 28.820492029190063 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.1465793212662814}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 4, 'n_estimators': 500, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_mean_squared_error = -119.57461957493719\n",
            "VARIANCE : 5.543822666558695 (fold 1 = -118.6469144662124, fold 2 = -126.78053984334767, fold 3 = -113.29640441525153)\n",
            "CPU time: 66.57991290092468 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.050543841983923234}\n",
            ">>> ESTIMATOR :{'strategy': 'AdaBoost', 'n_estimators': 250, 'base_estimator': None, 'learning_rate': 0.05, 'loss': 'linear', 'random_state': 0}\n",
            " 35%|███▌      | 7/20 [04:25<09:29, 43.84s/trial, best loss: 119.41289653897945]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlbox/model/regression/regressor.py:82: UserWarning: Invalid parameter for regressor AdaBoost. Parameter IGNORED. Check the list of available parameters with `regressor.get_params().keys()`\n",
            "  + \". Parameter IGNORED. Check the list of \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEAN SCORE : neg_mean_squared_error = -322.76086070362084\n",
            "VARIANCE : 0.5512347959429762 (fold 1 = -322.5527391312631, fold 2 = -322.21430350762665, fold 3 = -323.5155394719728)\n",
            "CPU time: 123.29912328720093 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.1232382042455423}\n",
            ">>> ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 5, 'n_estimators': 250, 'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
            "MEAN SCORE : neg_mean_squared_error = -382.3797886770367\n",
            "VARIANCE : 6.827589435775563 (fold 1 = -385.6125930728968, fold 2 = -388.6428343061344, fold 3 = -372.88393865207894)\n",
            "CPU time: 59.50560474395752 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.2138744578639977}\n",
            ">>> ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 4, 'n_estimators': 700, 'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
            "MEAN SCORE : neg_mean_squared_error = -418.22181657402047\n",
            "VARIANCE : 6.135840236977094 (fold 1 = -416.99751749387417, fold 2 = -426.2736315596849, fold 3 = -411.39430066850224)\n",
            "CPU time: 7.7603044509887695 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.04302138798039239}\n",
            ">>> ESTIMATOR :{'strategy': 'RandomForest', 'max_depth': 6, 'n_estimators': 500, 'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
            "MEAN SCORE : neg_mean_squared_error = -225.49108591464343\n",
            "VARIANCE : 6.27679526840508 (fold 1 = -222.51640058394332, fold 2 = -234.22140266870156, fold 3 = -219.73545449128537)\n",
            "CPU time: 27.480940103530884 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.290701184999186}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'n_estimators': 700, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_mean_squared_error = -105.4958057399657\n",
            "VARIANCE : 4.881444932151031 (fold 1 = -104.62688186938857, fold 2 = -111.86124444293684, fold 3 = -99.99929090757169)\n",
            "CPU time: 13.687381505966187 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.07053895309747708}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 3, 'n_estimators': 500, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_mean_squared_error = -137.74304670474476\n",
            "VARIANCE : 6.0456249789716345 (fold 1 = -136.46499176659148, fold 2 = -145.7032287112455, fold 3 = -131.06091963639733)\n",
            "CPU time: 61.2142550945282 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.011728537562478618}\n",
            ">>> ESTIMATOR :{'strategy': 'RandomForest', 'max_depth': 4, 'n_estimators': 250, 'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
            "MEAN SCORE : neg_mean_squared_error = -294.8385077446729\n",
            "VARIANCE : 5.57279065054738 (fold 1 = -291.1236476244695, fold 2 = -302.7153941064462, fold 3 = -290.6764815031029)\n",
            "CPU time: 10.279707908630371 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.14270489946971704}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 3, 'n_estimators': 500, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : neg_mean_squared_error = -137.3120699543182\n",
            "VARIANCE : 6.2256125413955345 (fold 1 = -136.87387510210473, fold 2 = -145.14650494529965, fold 3 = -129.91582981555018)\n",
            "CPU time: 6.01587700843811 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.05302657123833071}\n",
            ">>> ESTIMATOR :{'strategy': 'RandomForest', 'max_depth': 4, 'n_estimators': 700, 'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
            "MEAN SCORE : neg_mean_squared_error = -295.1041556686254\n",
            "VARIANCE : 6.239524153624828 (fold 1 = -292.48950584087675, fold 2 = -303.7101241005921, fold 3 = -289.11283706440736)\n",
            "CPU time: 84.99574637413025 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.2007064474240332}\n",
            ">>> ESTIMATOR :{'strategy': 'AdaBoost', 'n_estimators': 700, 'base_estimator': None, 'learning_rate': 0.05, 'loss': 'linear', 'random_state': 0}\n",
            " 80%|████████  | 16/20 [10:59<02:50, 42.60s/trial, best loss: 105.4958057399657]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlbox/model/regression/regressor.py:82: UserWarning: Invalid parameter for regressor AdaBoost. Parameter IGNORED. Check the list of available parameters with `regressor.get_params().keys()`\n",
            "  + \". Parameter IGNORED. Check the list of \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEAN SCORE : neg_mean_squared_error = -333.37516968959153\n",
            "VARIANCE : 7.583089069528471 (fold 1 = -325.67014595793376, fold 2 = -343.6875048289741, fold 3 = -330.76785828186667)\n",
            "CPU time: 220.29305744171143 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.21349156765022198}\n",
            ">>> ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 6, 'n_estimators': 500, 'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
            "MEAN SCORE : neg_mean_squared_error = -340.3165493488419\n",
            "VARIANCE : 6.724337044553679 (fold 1 = -340.96445900790616, fold 2 = -348.20905500046604, fold 3 = -331.7761340381534)\n",
            "CPU time: 61.22637987136841 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.23949445634442829}\n",
            ">>> ESTIMATOR :{'strategy': 'RandomForest', 'max_depth': 5, 'n_estimators': 250, 'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
            "MEAN SCORE : neg_mean_squared_error = -262.67881552252055\n",
            "VARIANCE : 5.7211121159258305 (fold 1 = -260.4510012893794, fold 2 = -270.52876885118394, fold 3 = -257.05667642699825)\n",
            "CPU time: 10.769171953201294 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.28167115571369117}\n",
            ">>> ESTIMATOR :{'strategy': 'AdaBoost', 'n_estimators': 700, 'base_estimator': None, 'learning_rate': 0.05, 'loss': 'linear', 'random_state': 0}\n",
            " 95%|█████████▌| 19/20 [15:52<01:03, 63.11s/trial, best loss: 105.4958057399657]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlbox/model/regression/regressor.py:82: UserWarning: Invalid parameter for regressor AdaBoost. Parameter IGNORED. Check the list of available parameters with `regressor.get_params().keys()`\n",
            "  + \". Parameter IGNORED. Check the list of \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEAN SCORE : neg_mean_squared_error = -339.934081498018\n",
            "VARIANCE : 12.799822153166705 (fold 1 = -337.6038039069579, fold 2 = -356.6452977888681, fold 3 = -325.5531427982279)\n",
            "CPU time: 131.39312148094177 seconds\n",
            "100%|██████████| 20/20 [18:03<00:00, 54.17s/trial, best loss: 105.4958057399657]\n",
            "\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ BEST HYPER-PARAMETERS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "{'est__max_depth': 5, 'est__n_estimators': 700, 'est__strategy': 'LightGBM', 'fs__strategy': 'l1', 'fs__threshold': 0.290701184999186, 'ne__numerical_strategy': 0}\n"
          ]
        }
      ],
      "source": [
        "best=opt.optimise(space,df,20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57SH0n2a5ruN"
      },
      "source": [
        "The ESTIMATOR line above gives the best model with fine-tuned hyper-parameters. \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toc = time.perf_counter()\n",
        "print (f\"Elapsed time {toc - tic:0.4f} seconds\")"
      ],
      "metadata": {
        "id": "zj06pN9IR25_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6df5e59-4f48-4466-dab1-ddcd0c222586"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time 1083.4102 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inference"
      ],
      "metadata": {
        "id": "IFbON60eY66c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19sZSJ3CGFyI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 664
        },
        "outputId": "8508c7d5-8106-4639-953e-96ebd2706953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "fitting the pipeline ...\n",
            "CPU time: 5.531095027923584 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "> Feature importances dumped into directory : save\n",
            "\n",
            "predicting...\n",
            "CPU time: 0.12866640090942383 seconds\n",
            "\n",
            "> Overview on predictions : \n",
            "\n",
            "   critical_temp_predicted\n",
            "0                 9.461727\n",
            "1                86.028325\n",
            "2                33.135221\n",
            "3                22.276576\n",
            "4                 6.609473\n",
            "5                59.639491\n",
            "6                80.178437\n",
            "7                57.142375\n",
            "8                33.789676\n",
            "9                17.965072\n",
            "\n",
            "dumping predictions into directory : save ...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mlbox.prediction.predictor.Predictor at 0x7fda61110cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "prd = Predictor()\n",
        "prd.fit_predict(best, df)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The predictions are stored in csv file"
      ],
      "metadata": {
        "id": "Ue_2ABF1QjBP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UzNurGC1GLmk"
      },
      "outputs": [],
      "source": [
        "class_predicted_mlbox=pd.read_csv('/content/save/critical_temp_predictions.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WadF0ykGLaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be71aabd-f3fa-44c9-a744-db0a2dfcee72"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        9.461727\n",
              "1       86.028325\n",
              "2       33.135221\n",
              "3       22.276576\n",
              "4        6.609473\n",
              "          ...    \n",
              "4248    80.874320\n",
              "4249    73.704579\n",
              "4250     3.876450\n",
              "4251    10.328666\n",
              "4252     5.448358\n",
              "Name: critical_temp_predicted, Length: 4253, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "class_predicted_mlbox['critical_temp_predicted'] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5rpnfUCjeB_y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba4d3b3b-c798-444f-de05-7376bb57e638"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((17010, 81), (4253, 81), (17010,), (4253,))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "X_train_regressor.shape, X_test_regressor.shape, label_train_regressor.shape, label_test_regressor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rvAQ401DGSCv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf6b883d-50d5-4bd2-8b98-f15bef8f158d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4253,), (4253,))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "label_test_regressor.shape, class_predicted_mlbox['critical_temp_predicted'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the error metrics"
      ],
      "metadata": {
        "id": "re45qpvgQ6Fy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jgYeFPlkiJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b24e1ab-07fd-4817-9369-872e0b2312fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE:  87.77266825021174\n",
            "RMSE:  9.36870686115281\n",
            "Coefficient of determination:  0.9237475817171334\n"
          ]
        }
      ],
      "source": [
        "error_metrics(label_test_regressor, class_predicted_mlbox['critical_temp_predicted'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmqZfAFCvL8W"
      },
      "source": [
        "## Biodegradation dataset (classification task)\n",
        "\n",
        "Source: https://archive.ics.uci.edu/ml/datasets/QSAR+biodegradation\n",
        "\n",
        "\n",
        "The dataset contains 21 numerical features (molecular attributes) of 1055 chemicals. The label corresponds to their experimental class (ready biodegradable \"RB\" or not ready biodegradable \"NRB\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M-s3EL0vkrx6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0714ed1-96f2-431f-aff0-c0da7d05c85d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-02 13:18:33--  https://raw.githubusercontent.com/abcom-mltutorials/automl/main/biodeg.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 155987 (152K) [text/plain]\n",
            "Saving to: ‘biodeg.csv’\n",
            "\n",
            "\rbiodeg.csv            0%[                    ]       0  --.-KB/s               \rbiodeg.csv          100%[===================>] 152.33K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2022-02-02 13:18:33 (64.6 MB/s) - ‘biodeg.csv’ saved [155987/155987]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://raw.githubusercontent.com/abcom-mltutorials/automl/main/biodeg.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3z80TjM8kNb"
      },
      "outputs": [],
      "source": [
        "classifier_df=pd.read_csv('/content/biodeg.csv', delimiter=';', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_df.shape"
      ],
      "metadata": {
        "id": "IJPcV2Igtwlu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5cafc5d-0fa6-4522-81f5-bfffd078824d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1055, 42)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njCToUld8kNe"
      },
      "outputs": [],
      "source": [
        "classifier_df.rename(columns={41:'label'}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "go8S2BJK8kNg"
      },
      "outputs": [],
      "source": [
        "classifier_df.columns = classifier_df.columns.astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJdaGiAK8kNi"
      },
      "outputs": [],
      "source": [
        "features_classifier = classifier_df.iloc[:,:-1]\n",
        "label_classifier = classifier_df.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following couple of cells are to balance the label: "
      ],
      "metadata": {
        "id": "tlDmSKl_RlXu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kkk7_G-Z8kNl"
      },
      "outputs": [],
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ny7eshsU8kNn"
      },
      "outputs": [],
      "source": [
        "sm = SMOTE(random_state=42)\n",
        "X_classifier, y_classifier = sm.fit_resample(features_classifier, label_classifier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EOZVdb5K8kNq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "360845c8-57f5-4748-ccf1-8351607d926c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RB     699\n",
              "NRB    699\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "y_classifier.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZyfq9x18kNs"
      },
      "outputs": [],
      "source": [
        "y_classifier = y_classifier.replace('NRB',0).replace('RB',1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kIoTX5cd8kNx"
      },
      "outputs": [],
      "source": [
        "X_train_classifier, X_test_classifier, label_train_classifier, label_test_classifier = train_test_split(X_classifier, y_classifier, random_state=42, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GAqn8l7QQ7W"
      },
      "source": [
        "## Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eked3SBuHd7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ae0fdec-135a-4a10-f97e-21494fd1fb69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1118, 41), (1118, 41))"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "X_train_classifier.shape, X_train_classifier.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvX7QuWUbQsC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "outputId": "5c6f1e50-2938-4dc2-f319-c8ea2ffc66d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e2c33d6d-b306-4297-b3cd-1a64b6fa6ffe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>4.644000</td>\n",
              "      <td>3.907100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>31.600000</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.104</td>\n",
              "      <td>3.08200</td>\n",
              "      <td>1.837000</td>\n",
              "      <td>9.467000</td>\n",
              "      <td>5</td>\n",
              "      <td>1.021000</td>\n",
              "      <td>1.142000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.149000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.084000</td>\n",
              "      <td>0.049000</td>\n",
              "      <td>0</td>\n",
              "      <td>10.469</td>\n",
              "      <td>2.732000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.525000</td>\n",
              "      <td>3.093000</td>\n",
              "      <td>0</td>\n",
              "      <td>7.886000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>5.156000</td>\n",
              "      <td>2.452400</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>55.600000</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>-3.296</td>\n",
              "      <td>3.78800</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>10.813000</td>\n",
              "      <td>16</td>\n",
              "      <td>1.103000</td>\n",
              "      <td>1.093000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.225000</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.532000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>44.736</td>\n",
              "      <td>1.508000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.986000</td>\n",
              "      <td>3.271000</td>\n",
              "      <td>0</td>\n",
              "      <td>9.007000</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>756</th>\n",
              "      <td>4.414000</td>\n",
              "      <td>4.388300</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>9.100000</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.662</td>\n",
              "      <td>2.94600</td>\n",
              "      <td>1.379000</td>\n",
              "      <td>9.222000</td>\n",
              "      <td>2</td>\n",
              "      <td>1.097000</td>\n",
              "      <td>1.219000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.074000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.171000</td>\n",
              "      <td>0</td>\n",
              "      <td>18.567</td>\n",
              "      <td>2.133000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>3.689000</td>\n",
              "      <td>4.167000</td>\n",
              "      <td>4</td>\n",
              "      <td>8.139000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1070</th>\n",
              "      <td>4.503037</td>\n",
              "      <td>3.037476</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>43.418742</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.01153</td>\n",
              "      <td>1.188692</td>\n",
              "      <td>9.328942</td>\n",
              "      <td>2</td>\n",
              "      <td>0.990103</td>\n",
              "      <td>1.117673</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.252776</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.138916</td>\n",
              "      <td>0.029301</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.605469</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.573224</td>\n",
              "      <td>2.129853</td>\n",
              "      <td>0</td>\n",
              "      <td>7.889213</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>5.029000</td>\n",
              "      <td>1.686400</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>38.800000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0.000</td>\n",
              "      <td>4.12800</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>10.839000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.979000</td>\n",
              "      <td>1.119000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.308000</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.418000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.219000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>4.348000</td>\n",
              "      <td>1.710000</td>\n",
              "      <td>2</td>\n",
              "      <td>9.423000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2c33d6d-b306-4297-b3cd-1a64b6fa6ffe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e2c33d6d-b306-4297-b3cd-1a64b6fa6ffe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e2c33d6d-b306-4297-b3cd-1a64b6fa6ffe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             0         1  2  3  4  5  ...        35        36  37        38  39  40\n",
              "48    4.644000  3.907100  0  0  0  0  ...  3.525000  3.093000   0  7.886000   0   0\n",
              "155   5.156000  2.452400  0  0  0  0  ...  3.986000  3.271000   0  9.007000   4   0\n",
              "756   4.414000  4.388300  0  1  0  0  ...  3.689000  4.167000   4  8.139000   0   0\n",
              "1070  4.503037  3.037476  0  0  0  0  ...  3.573224  2.129853   0  7.889213   0   0\n",
              "303   5.029000  1.686400  2  0  7  0  ...  4.348000  1.710000   2  9.423000   0   0\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "X_train_classifier.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz5cMwuWbNKO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "40d9d103-89fc-4343-e7f5-fc39dfae1691"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'label'"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "label_train_classifier.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApJ4TbVFbNKS"
      },
      "outputs": [],
      "source": [
        "training2 = pd.concat([X_train_classifier, label_train_classifier], axis=1)\n",
        "testing2 = X_test_classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gaCxzpR7Hd7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11d05e6e-5c1f-45d9-d8ad-bb34106a0657"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(pandas.core.frame.DataFrame, pandas.core.frame.DataFrame)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "type(training2), type(testing2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create training/testing csv files"
      ],
      "metadata": {
        "id": "Vtwkf2PsZitN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0z3DRz_FHd7W"
      },
      "outputs": [],
      "source": [
        "training2.to_csv('training2_file.csv')\n",
        "testing2.to_csv('testing2_file.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use Reader to load files"
      ],
      "metadata": {
        "id": "l6W9ZQnjSR-s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZXzjyFpIzyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27829724-2baa-4830-f0ec-7bda77e203ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "reading csv : training2_file.csv ...\n",
            "cleaning data ...\n",
            "CPU time: 0.1522533893585205 seconds\n",
            "\n",
            "reading csv : testing2_file.csv ...\n",
            "cleaning data ...\n",
            "CPU time: 0.13157343864440918 seconds\n",
            "\n",
            "> Number of common features : 41\n",
            "\n",
            "gathering and crunching for train and test datasets ...\n",
            "reindexing for train and test datasets ...\n",
            "dropping training duplicates ...\n",
            "dropping constant variables on training set ...\n",
            "\n",
            "> Number of categorical features: 0\n",
            "> Number of numerical features: 41\n",
            "> Number of training samples : 1116\n",
            "> Number of test samples : 280\n",
            "\n",
            "> You have no missing values on train set...\n",
            "\n",
            "> Task : classification\n",
            "1.0    561\n",
            "0.0    555\n",
            "Name: label, dtype: int64\n",
            "\n",
            "encoding target ...\n"
          ]
        }
      ],
      "source": [
        "paths=['training2_file.csv', 'testing2_file.csv']\n",
        "rd = Reader(sep = ',')\n",
        "df2 = rd.train_test_split(paths, target_name='label')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Drop the biased columns"
      ],
      "metadata": {
        "id": "MXjxMM8VSax8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tilEsbWDIzyi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b0dade1-6bb0-4d63-83ae-b8a8698aef12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "computing drifts ...\n",
            "CPU time: 0.6580839157104492 seconds\n",
            "\n",
            "> Top 10 drifts\n",
            "\n",
            "('7', 0.06742191500256034)\n",
            "('37', 0.06036226318484372)\n",
            "('30', 0.04993599590373776)\n",
            "('4', 0.04954557091653866)\n",
            "('32', 0.048105478750640085)\n",
            "('8', 0.046505376344085914)\n",
            "('26', 0.04584613415258598)\n",
            "('40', 0.04480926779313865)\n",
            "('10', 0.043958013312852096)\n",
            "('14', 0.04242191500256021)\n",
            "\n",
            "> Deleted variables : []\n",
            "> Drift coefficients dumped into directory : save\n"
          ]
        }
      ],
      "source": [
        "dft = Drift_thresholder()\n",
        "df2 = dft.fit_transform(df2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "No columns are dropped. Set the range of values for various hyper-parameters"
      ],
      "metadata": {
        "id": "10XC8boPSjTE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEtM44yDIzyj"
      },
      "outputs": [],
      "source": [
        "space = {'ne__numerical_strategy':{\"space\":[0]},\n",
        "        'fs__strategy':{\"search\":\"choice\",\n",
        "                        \"space\":['l1','variance','rf_feature_importance']},\n",
        "        'fs__threshold':{\"search\":\"uniform\",\n",
        "                        \"space\":[0.01,0.3]},\n",
        "        'est__strategy' : {\"search\":\"choice\",\n",
        "                           \"space\" : ['LightGBM', 'RandomForest', 'ExtraTrees', 'AdaBoost']},    \n",
        "        'est__max_depth':{\"search\":\"choice\",\n",
        "                          \"space\":[3,4,5,6]},\n",
        "        'est__n_estimators':{\"search\":\"choice\",\n",
        "                             \"space\":[250,500,700]}}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create optimizer"
      ],
      "metadata": {
        "id": "cyhlqfHaS09A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zaks0lCrIzyk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5589c7e8-016b-4ffb-ba87-a4accb22cedf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlbox/optimisation/optimiser.py:74: UserWarning: Optimiser will save all your fitted models into directory 'save/joblib'. Please clear it regularly.\n",
            "  +str(self.to_path)+\"/joblib'. Please clear it regularly.\")\n"
          ]
        }
      ],
      "source": [
        "opt=Optimiser(scoring=\"accuracy\", n_folds=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate optimizer on a single trial"
      ],
      "metadata": {
        "id": "HcdWeu-nS6SQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tYUT3t3yIzyl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d5c8963-58e1-43ab-b489-53044a977f9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No parameters set. Default configuration is tested\n",
            "\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            "\n",
            ">>> NA ENCODER :{'numerical_strategy': 'mean', 'categorical_strategy': '<NULL>'}\n",
            "\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            "\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'max_depth': -1, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_estimators': 500, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "\n",
            "\n",
            "MEAN SCORE : accuracy = 0.8853046594982078\n",
            "VARIANCE : 0.010827102126876847 (fold 1 = 0.9005376344086021, fold 2 = 0.8763440860215054, fold 3 = 0.8790322580645161)\n",
            "CPU time: 2.294726610183716 seconds\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8853046594982078"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "opt.evaluate(None, df2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run optimizer for 20 trials"
      ],
      "metadata": {
        "id": "5T33KmVCTBoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "tic = time.perf_counter()"
      ],
      "metadata": {
        "id": "ISL4W7TRSM5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w2C7Hp3BIzym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "541a20cf-e8e1-49d7-9760-057982f1a0ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.06878971424932297}\n",
            ">>> ESTIMATOR :{'strategy': 'AdaBoost', 'n_estimators': 250, 'algorithm': 'SAMME.R', 'base_estimator': None, 'learning_rate': 0.05, 'random_state': 0}\n",
            "  0%|          | 0/20 [00:00<?, ?trial/s, best loss=?]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlbox/model/classification/classifier.py:92: UserWarning: Invalid parameter for classifier AdaBoost. Parameter IGNORED. Check the list of available parameters with `classifier.get_params().keys()`\n",
            "  + \". Parameter IGNORED. Check the list of \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEAN SCORE : accuracy = 0.8629032258064516\n",
            "VARIANCE : 0.019008246806089972 (fold 1 = 0.8763440860215054, fold 2 = 0.8763440860215054, fold 3 = 0.8360215053763441)\n",
            "CPU time: 2.088958501815796 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.23017272079683318}\n",
            ">>> ESTIMATOR :{'strategy': 'AdaBoost', 'n_estimators': 250, 'algorithm': 'SAMME.R', 'base_estimator': None, 'learning_rate': 0.05, 'random_state': 0}\n",
            "  5%|▌         | 1/20 [00:02<00:39,  2.10s/trial, best loss: -0.8629032258064516]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlbox/model/classification/classifier.py:92: UserWarning: Invalid parameter for classifier AdaBoost. Parameter IGNORED. Check the list of available parameters with `classifier.get_params().keys()`\n",
            "  + \". Parameter IGNORED. Check the list of \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEAN SCORE : accuracy = 0.8611111111111112\n",
            "VARIANCE : 0.014280804167122952 (fold 1 = 0.8602150537634409, fold 2 = 0.8790322580645161, fold 3 = 0.8440860215053764)\n",
            "CPU time: 2.8643689155578613 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.13105671802566984}\n",
            ">>> ESTIMATOR :{'strategy': 'RandomForest', 'max_depth': 4, 'n_estimators': 700, 'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
            "MEAN SCORE : accuracy = 0.8611111111111112\n",
            "VARIANCE : 0.01774103035235064 (fold 1 = 0.8413978494623656, fold 2 = 0.8844086021505376, fold 3 = 0.8575268817204301)\n",
            "CPU time: 4.304877758026123 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.07077914827762995}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 4, 'n_estimators': 250, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : accuracy = 0.8826164874551972\n",
            "VARIANCE : 0.01104733692288346 (fold 1 = 0.8951612903225806, fold 2 = 0.8844086021505376, fold 3 = 0.8682795698924731)\n",
            "CPU time: 0.4814765453338623 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.07564542621313877}\n",
            ">>> ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 3, 'n_estimators': 700, 'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
            "MEAN SCORE : accuracy = 0.8234767025089607\n",
            "VARIANCE : 0.02864581964721468 (fold 1 = 0.8198924731182796, fold 2 = 0.8602150537634409, fold 3 = 0.7903225806451613)\n",
            "CPU time: 4.208197355270386 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.046917159202616285}\n",
            ">>> ESTIMATOR :{'strategy': 'AdaBoost', 'n_estimators': 250, 'algorithm': 'SAMME.R', 'base_estimator': None, 'learning_rate': 0.05, 'random_state': 0}\n",
            " 25%|██▌       | 5/20 [00:14<00:44,  2.95s/trial, best loss: -0.8826164874551972]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlbox/model/classification/classifier.py:92: UserWarning: Invalid parameter for classifier AdaBoost. Parameter IGNORED. Check the list of available parameters with `classifier.get_params().keys()`\n",
            "  + \". Parameter IGNORED. Check the list of \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEAN SCORE : accuracy = 0.8611111111111112\n",
            "VARIANCE : 0.014280804167122952 (fold 1 = 0.8602150537634409, fold 2 = 0.8790322580645161, fold 3 = 0.8440860215053764)\n",
            "CPU time: 2.8967745304107666 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.06425825850380303}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'n_estimators': 700, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : accuracy = 0.8870967741935484\n",
            "VARIANCE : 0.00877953312825511 (fold 1 = 0.8978494623655914, fold 2 = 0.8870967741935484, fold 3 = 0.8763440860215054)\n",
            "CPU time: 1.3680613040924072 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.2518759454756328}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 3, 'n_estimators': 500, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : accuracy = 0.8862007168458782\n",
            "VARIANCE : 0.010827102126876847 (fold 1 = 0.8951612903225806, fold 2 = 0.8924731182795699, fold 3 = 0.8709677419354839)\n",
            "CPU time: 0.576836109161377 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.21499210909469824}\n",
            ">>> ESTIMATOR :{'strategy': 'AdaBoost', 'n_estimators': 700, 'algorithm': 'SAMME.R', 'base_estimator': None, 'learning_rate': 0.05, 'random_state': 0}\n",
            " 40%|████      | 8/20 [00:18<00:22,  1.85s/trial, best loss: -0.8870967741935484]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlbox/model/classification/classifier.py:92: UserWarning: Invalid parameter for classifier AdaBoost. Parameter IGNORED. Check the list of available parameters with `classifier.get_params().keys()`\n",
            "  + \". Parameter IGNORED. Check the list of \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEAN SCORE : accuracy = 0.8790322580645161\n",
            "VARIANCE : 0.005807115321153991 (fold 1 = 0.8817204301075269, fold 2 = 0.8844086021505376, fold 3 = 0.8709677419354839)\n",
            "CPU time: 6.223439931869507 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.18901776252787036}\n",
            ">>> ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 5, 'n_estimators': 250, 'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
            "MEAN SCORE : accuracy = 0.8405017921146953\n",
            "VARIANCE : 0.02636906625369565 (fold 1 = 0.8387096774193549, fold 2 = 0.8736559139784946, fold 3 = 0.8091397849462365)\n",
            "CPU time: 2.029357671737671 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.03729949079479158}\n",
            ">>> ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 5, 'n_estimators': 500, 'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
            "MEAN SCORE : accuracy = 0.8458781362007168\n",
            "VARIANCE : 0.02524910896703469 (fold 1 = 0.8467741935483871, fold 2 = 0.8763440860215054, fold 3 = 0.8145161290322581)\n",
            "CPU time: 3.7848472595214844 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.026266801034034094}\n",
            ">>> ESTIMATOR :{'strategy': 'AdaBoost', 'n_estimators': 250, 'algorithm': 'SAMME.R', 'base_estimator': None, 'learning_rate': 0.05, 'random_state': 0}\n",
            " 55%|█████▌    | 11/20 [00:31<00:28,  3.15s/trial, best loss: -0.8870967741935484]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlbox/model/classification/classifier.py:92: UserWarning: Invalid parameter for classifier AdaBoost. Parameter IGNORED. Check the list of available parameters with `classifier.get_params().keys()`\n",
            "  + \". Parameter IGNORED. Check the list of \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEAN SCORE : accuracy = 0.8611111111111112\n",
            "VARIANCE : 0.014280804167122952 (fold 1 = 0.8602150537634409, fold 2 = 0.8790322580645161, fold 3 = 0.8440860215053764)\n",
            "CPU time: 2.9158947467803955 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.18922143044353415}\n",
            ">>> ESTIMATOR :{'strategy': 'ExtraTrees', 'max_depth': 6, 'n_estimators': 700, 'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
            "MEAN SCORE : accuracy = 0.8575268817204301\n",
            "VARIANCE : 0.031117841136532837 (fold 1 = 0.8709677419354839, fold 2 = 0.8870967741935484, fold 3 = 0.8145161290322581)\n",
            "CPU time: 4.400055885314941 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.2349674174175576}\n",
            ">>> ESTIMATOR :{'strategy': 'AdaBoost', 'n_estimators': 700, 'algorithm': 'SAMME.R', 'base_estimator': None, 'learning_rate': 0.05, 'random_state': 0}\n",
            " 65%|██████▌   | 13/20 [00:38<00:24,  3.49s/trial, best loss: -0.8870967741935484]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlbox/model/classification/classifier.py:92: UserWarning: Invalid parameter for classifier AdaBoost. Parameter IGNORED. Check the list of available parameters with `classifier.get_params().keys()`\n",
            "  + \". Parameter IGNORED. Check the list of \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEAN SCORE : accuracy = 0.8790322580645161\n",
            "VARIANCE : 0.005807115321153991 (fold 1 = 0.8817204301075269, fold 2 = 0.8844086021505376, fold 3 = 0.8709677419354839)\n",
            "CPU time: 6.2288432121276855 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.23250542555732184}\n",
            ">>> ESTIMATOR :{'strategy': 'AdaBoost', 'n_estimators': 250, 'algorithm': 'SAMME.R', 'base_estimator': None, 'learning_rate': 0.05, 'random_state': 0}\n",
            " 70%|███████   | 14/20 [00:44<00:25,  4.32s/trial, best loss: -0.8870967741935484]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlbox/model/classification/classifier.py:92: UserWarning: Invalid parameter for classifier AdaBoost. Parameter IGNORED. Check the list of available parameters with `classifier.get_params().keys()`\n",
            "  + \". Parameter IGNORED. Check the list of \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEAN SCORE : accuracy = 0.8602150537634409\n",
            "VARIANCE : 0.02291525421602941 (fold 1 = 0.8736559139784946, fold 2 = 0.8790322580645161, fold 3 = 0.8279569892473119)\n",
            "CPU time: 1.9491219520568848 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.24512410988227634}\n",
            ">>> ESTIMATOR :{'strategy': 'AdaBoost', 'n_estimators': 700, 'algorithm': 'SAMME.R', 'base_estimator': None, 'learning_rate': 0.05, 'random_state': 0}\n",
            " 75%|███████▌  | 15/20 [00:46<00:18,  3.61s/trial, best loss: -0.8870967741935484]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/mlbox/model/classification/classifier.py:92: UserWarning: Invalid parameter for classifier AdaBoost. Parameter IGNORED. Check the list of available parameters with `classifier.get_params().keys()`\n",
            "  + \". Parameter IGNORED. Check the list of \"\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MEAN SCORE : accuracy = 0.8754480286738352\n",
            "VARIANCE : 0.01866726402867351 (fold 1 = 0.8844086021505376, fold 2 = 0.8924731182795699, fold 3 = 0.8494623655913979)\n",
            "CPU time: 5.470525741577148 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'rf_feature_importance', 'threshold': 0.19995432442661312}\n",
            ">>> ESTIMATOR :{'strategy': 'RandomForest', 'max_depth': 5, 'n_estimators': 500, 'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
            "MEAN SCORE : accuracy = 0.8709677419354839\n",
            "VARIANCE : 0.019508549334298585 (fold 1 = 0.8629032258064516, fold 2 = 0.8978494623655914, fold 3 = 0.8521505376344086)\n",
            "CPU time: 4.22569465637207 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'variance', 'threshold': 0.14750276806010643}\n",
            ">>> ESTIMATOR :{'strategy': 'RandomForest', 'max_depth': 5, 'n_estimators': 500, 'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_jobs': -1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n",
            "MEAN SCORE : accuracy = 0.8691756272401433\n",
            "VARIANCE : 0.01661938798475931 (fold 1 = 0.8548387096774194, fold 2 = 0.8924731182795699, fold 3 = 0.8602150537634409)\n",
            "CPU time: 3.5082855224609375 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.12268756034465307}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 3, 'n_estimators': 250, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : accuracy = 0.8870967741935484\n",
            "VARIANCE : 0.010974416410318889 (fold 1 = 0.8870967741935484, fold 2 = 0.9005376344086021, fold 3 = 0.8736559139784946)\n",
            "CPU time: 0.7642509937286377 seconds\n",
            "##################################################### testing hyper-parameters... #####################################################\n",
            ">>> NA ENCODER :{'numerical_strategy': 0, 'categorical_strategy': '<NULL>'}\n",
            ">>> CA ENCODER :{'strategy': 'label_encoding'}\n",
            ">>> FEATURE SELECTOR :{'strategy': 'l1', 'threshold': 0.02331793880206877}\n",
            ">>> ESTIMATOR :{'strategy': 'LightGBM', 'max_depth': 5, 'n_estimators': 700, 'boosting_type': 'gbdt', 'class_weight': None, 'colsample_bytree': 0.8, 'importance_type': 'split', 'learning_rate': 0.05, 'min_child_samples': 20, 'min_child_weight': 0.001, 'min_split_gain': 0.0, 'n_jobs': -1, 'num_leaves': 31, 'objective': None, 'random_state': None, 'reg_alpha': 0.0, 'reg_lambda': 0.0, 'silent': True, 'subsample': 0.9, 'subsample_for_bin': 200000, 'subsample_freq': 0, 'nthread': -1, 'seed': 0}\n",
            "MEAN SCORE : accuracy = 0.8772401433691757\n",
            "VARIANCE : 0.013410958375533829 (fold 1 = 0.8951612903225806, fold 2 = 0.8736559139784946, fold 3 = 0.8629032258064516)\n",
            "CPU time: 1.7768113613128662 seconds\n",
            "100%|██████████| 20/20 [01:02<00:00,  3.12s/trial, best loss: -0.8870967741935484]\n",
            "\n",
            "\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ BEST HYPER-PARAMETERS ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
            "\n",
            "{'est__max_depth': 5, 'est__n_estimators': 700, 'est__strategy': 'LightGBM', 'fs__strategy': 'variance', 'fs__threshold': 0.06425825850380303, 'ne__numerical_strategy': 0}\n"
          ]
        }
      ],
      "source": [
        "best=opt.optimise(space,df2,20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "toc = time.perf_counter()\n",
        "print (f\"Elapsed time {toc - tic:0.4f} seconds\")"
      ],
      "metadata": {
        "id": "Eisv1bH2SmDL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70a5f8a2-273a-4d3d-87da-dd448a28d12a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elapsed time 62.4687 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ESTIMATOR gives the best model with fine-tuned hyper-parameters"
      ],
      "metadata": {
        "id": "co1dNVwTTKev"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNCFV-0wIzyn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "2aba1931-7b27-4226-8078-771eb91e05d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "fitting the pipeline ...\n",
            "CPU time: 0.6199147701263428 seconds\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "> Feature importances dumped into directory : save\n",
            "\n",
            "predicting ...\n",
            "CPU time: 0.037960052490234375 seconds\n",
            "\n",
            "> Overview on predictions : \n",
            "\n",
            "        0.0       1.0  label_predicted\n",
            "0  0.998554  0.001446                0\n",
            "1  0.456869  0.543131                1\n",
            "2  0.995760  0.004240                0\n",
            "3  0.375087  0.624913                1\n",
            "4  0.000260  0.999740                1\n",
            "5  0.702108  0.297892                0\n",
            "6  0.006592  0.993408                1\n",
            "7  0.999997  0.000003                0\n",
            "8  0.996638  0.003362                0\n",
            "9  0.000781  0.999219                1\n",
            "\n",
            "dumping predictions into directory : save ...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<mlbox.prediction.predictor.Predictor at 0x7fda5a7bc710>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "prd = Predictor()\n",
        "prd.fit_predict(best, df2)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictions are stored in csv file"
      ],
      "metadata": {
        "id": "-CCB12k2TYhk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGLdfRWON8SR"
      },
      "outputs": [],
      "source": [
        "reg_predicted_mlbox=pd.read_csv('/content/save/label_predictions.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgmNl_dyOvrr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ce75b7f-6238-4013-89bf-81de732e4acb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      1\n",
              "2      0\n",
              "3      1\n",
              "4      1\n",
              "      ..\n",
              "275    0\n",
              "276    0\n",
              "277    0\n",
              "278    1\n",
              "279    1\n",
              "Name: label_predicted, Length: 280, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "reg_predicted_mlbox['label_predicted'] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIOfN1dxO4zv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf5a43c9-689d-44a5-eea2-3bda97ca13e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((280,), (280,))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "label_test_classifier.shape, reg_predicted_mlbox['label_predicted'].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the classification report"
      ],
      "metadata": {
        "id": "KzAW7qBtTiou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "92iFPOJ_cms0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5o9G4SmuLVTM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a7ed300-30bc-4c9b-94a3-b7ebf96cca62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.93      0.92       138\n",
            "           1       0.93      0.90      0.92       142\n",
            "\n",
            "    accuracy                           0.92       280\n",
            "   macro avg       0.92      0.92      0.92       280\n",
            "weighted avg       0.92      0.92      0.92       280\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(reg_predicted_mlbox['label_predicted'], label_test_classifier))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "AutoML MLBox.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}